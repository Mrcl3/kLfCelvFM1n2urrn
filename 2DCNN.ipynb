{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3skq5edU4P"
      },
      "source": [
        "# 2D CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qb2uSyKh24DS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation, Rescaling, BatchNormalization, Conv3D, MaxPool3D, Dropout\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow.keras as keras\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0YqnkQaO3T5k"
      },
      "source": [
        "## Declaring the repositories with images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b5H1KmZ_27Mk"
      },
      "outputs": [],
      "source": [
        "# Assuming your image folder is called 'dataset' and contains two subfolders: 'flipped' and 'noflipped'\n",
        "flipped_dir = r'C:\\Users\\mbajd\\Downloads\\images\\images\\training\\flip'\n",
        "noflipped_dir = r'C:\\Users\\mbajd\\Downloads\\images\\images\\training\\notflip'\n",
        "test_dir = r'C:\\Users\\mbajd\\Downloads\\images\\images\\testing'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rMcrfp8a3QVj"
      },
      "source": [
        "## Loading the images for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZRiKu44J2961"
      },
      "outputs": [],
      "source": [
        "# Load the image paths from the 'flipped' and 'noflipped' subfolders\n",
        "flipped_images = glob.glob(flipped_dir + '/*.jpg')  # Assuming your images have the .jpg extension\n",
        "noflipped_images = glob.glob(noflipped_dir + '/*.jpg')\n",
        "\n",
        "# Assuming you have your labels as 'flipped' and 'noflipped'\n",
        "flipped_labels = ['flip'] * len(flipped_images)\n",
        "noflipped_labels = ['noflip'] * len(noflipped_images)\n",
        "\n",
        "# Concatenate the flipped and noflipped images and labels\n",
        "images = flipped_images + noflipped_images\n",
        "labels = flipped_labels + noflipped_labels\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K6rP6qiF3beW"
      },
      "source": [
        "## Organizing train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "8ZzfJOjc3ZbS"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the test images and labels\n",
        "test_flipped_images = glob.glob(test_dir + '/flip/*.jpg')\n",
        "test_noflipped_images = glob.glob(test_dir + '/notflip/*.jpg')\n",
        "\n",
        "test_images = test_flipped_images + test_noflipped_images\n",
        "test_labels = ['flip'] * len(test_flipped_images) + ['noflip'] * len(test_noflipped_images)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W-eBdwor3gCq"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iMFPPxr4BE3"
      },
      "outputs": [],
      "source": [
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Convert labels to binary representation (0 for flipped, 1 for noflipped)\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "val_labels = label_encoder.transform(val_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, input_shape[:2])\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Load and preprocess the training, validation, and test images\n",
        "train_images = np.array([preprocess_image(image_path) for image_path in train_images])\n",
        "val_images = np.array([preprocess_image(image_path) for image_path in val_images])\n",
        "test_images = np.array([preprocess_image(image_path) for image_path in test_images])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cu8Tuerg4Ej_"
      },
      "source": [
        "## ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    #horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=batch_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OMrXEEt-4I8O"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ehx_uxN4OCN"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.MaxPool2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output neuron for binary classification\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8mJkK_RD4Pgo"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdEQN9bo4Rho",
        "outputId": "66e85e79-79fe-465e-dfbd-7708ccb36850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               66048     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 323,649\n",
            "Trainable params: 323,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5YM0xSXC4Vyw"
      },
      "source": [
        "## Model compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQkEo0JRfjNB",
        "outputId": "a216daf9-0516-426a-cd30-5ec4965e92d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "15/15 [==============================] - 4s 154ms/step - loss: 0.6931 - binary_accuracy: 0.5013 - val_loss: 0.6920 - val_binary_accuracy: 0.5240\n",
            "Epoch 2/80\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.6922 - binary_accuracy: 0.5165 - val_loss: 0.6920 - val_binary_accuracy: 0.5240\n",
            "Epoch 3/80\n",
            "15/15 [==============================] - 4s 255ms/step - loss: 0.6927 - binary_accuracy: 0.5102 - val_loss: 0.6918 - val_binary_accuracy: 0.5240\n",
            "Epoch 4/80\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.6922 - binary_accuracy: 0.5159 - val_loss: 0.6912 - val_binary_accuracy: 0.5240\n",
            "Epoch 5/80\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.6918 - binary_accuracy: 0.5165 - val_loss: 0.6908 - val_binary_accuracy: 0.5240\n",
            "Epoch 6/80\n",
            "15/15 [==============================] - 4s 226ms/step - loss: 0.6932 - binary_accuracy: 0.5144 - val_loss: 0.6912 - val_binary_accuracy: 0.5240\n",
            "Epoch 7/80\n",
            "15/15 [==============================] - 3s 183ms/step - loss: 0.6924 - binary_accuracy: 0.5170 - val_loss: 0.6907 - val_binary_accuracy: 0.5240\n",
            "Epoch 8/80\n",
            "15/15 [==============================] - 3s 169ms/step - loss: 0.6922 - binary_accuracy: 0.5196 - val_loss: 0.6905 - val_binary_accuracy: 0.5240\n",
            "Epoch 9/80\n",
            "15/15 [==============================] - 3s 173ms/step - loss: 0.6917 - binary_accuracy: 0.5144 - val_loss: 0.6902 - val_binary_accuracy: 0.5240\n",
            "Epoch 10/80\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.6912 - binary_accuracy: 0.5254 - val_loss: 0.6899 - val_binary_accuracy: 0.5240\n",
            "Epoch 11/80\n",
            "15/15 [==============================] - 3s 169ms/step - loss: 0.6908 - binary_accuracy: 0.5264 - val_loss: 0.6892 - val_binary_accuracy: 0.5240\n",
            "Epoch 12/80\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.6895 - binary_accuracy: 0.5238 - val_loss: 0.6886 - val_binary_accuracy: 0.5240\n",
            "Epoch 13/80\n",
            "15/15 [==============================] - 4s 235ms/step - loss: 0.6899 - binary_accuracy: 0.5489 - val_loss: 0.6881 - val_binary_accuracy: 0.5574\n",
            "Epoch 14/80\n",
            "15/15 [==============================] - 3s 180ms/step - loss: 0.6895 - binary_accuracy: 0.5452 - val_loss: 0.6871 - val_binary_accuracy: 0.5595\n",
            "Epoch 15/80\n",
            "15/15 [==============================] - 3s 183ms/step - loss: 0.6891 - binary_accuracy: 0.5536 - val_loss: 0.6855 - val_binary_accuracy: 0.5637\n",
            "Epoch 16/80\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.6895 - binary_accuracy: 0.5374 - val_loss: 0.6840 - val_binary_accuracy: 0.6180\n",
            "Epoch 17/80\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.6874 - binary_accuracy: 0.5672 - val_loss: 0.6820 - val_binary_accuracy: 0.6054\n",
            "Epoch 18/80\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.6859 - binary_accuracy: 0.5677 - val_loss: 0.6799 - val_binary_accuracy: 0.6409\n",
            "Epoch 19/80\n",
            "15/15 [==============================] - 3s 181ms/step - loss: 0.6829 - binary_accuracy: 0.5964 - val_loss: 0.6785 - val_binary_accuracy: 0.7537\n",
            "Epoch 20/80\n",
            "15/15 [==============================] - 3s 205ms/step - loss: 0.6813 - binary_accuracy: 0.6116 - val_loss: 0.6724 - val_binary_accuracy: 0.7578\n",
            "Epoch 21/80\n",
            "15/15 [==============================] - 3s 195ms/step - loss: 0.6787 - binary_accuracy: 0.6048 - val_loss: 0.6657 - val_binary_accuracy: 0.7223\n",
            "Epoch 22/80\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.6734 - binary_accuracy: 0.6210 - val_loss: 0.6576 - val_binary_accuracy: 0.6639\n",
            "Epoch 23/80\n",
            "15/15 [==============================] - 3s 182ms/step - loss: 0.6652 - binary_accuracy: 0.6451 - val_loss: 0.6412 - val_binary_accuracy: 0.6827\n",
            "Epoch 24/80\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.6528 - binary_accuracy: 0.6566 - val_loss: 0.6215 - val_binary_accuracy: 0.7411\n",
            "Epoch 25/80\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.6402 - binary_accuracy: 0.6681 - val_loss: 0.6005 - val_binary_accuracy: 0.6952\n",
            "Epoch 26/80\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.6061 - binary_accuracy: 0.7026 - val_loss: 0.5698 - val_binary_accuracy: 0.7537\n",
            "Epoch 27/80\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.5870 - binary_accuracy: 0.7177 - val_loss: 0.5435 - val_binary_accuracy: 0.7432\n",
            "Epoch 28/80\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.5889 - binary_accuracy: 0.6932 - val_loss: 0.5469 - val_binary_accuracy: 0.7411\n",
            "Epoch 29/80\n",
            "15/15 [==============================] - 3s 204ms/step - loss: 0.5950 - binary_accuracy: 0.6926 - val_loss: 0.5251 - val_binary_accuracy: 0.7537\n",
            "Epoch 30/80\n",
            "15/15 [==============================] - 3s 184ms/step - loss: 0.5865 - binary_accuracy: 0.6843 - val_loss: 0.6849 - val_binary_accuracy: 0.6242\n",
            "Epoch 31/80\n",
            "15/15 [==============================] - 3s 167ms/step - loss: 0.5957 - binary_accuracy: 0.6827 - val_loss: 0.5159 - val_binary_accuracy: 0.7704\n",
            "Epoch 32/80\n",
            "15/15 [==============================] - 3s 203ms/step - loss: 0.5304 - binary_accuracy: 0.7574 - val_loss: 0.4670 - val_binary_accuracy: 0.7829\n",
            "Epoch 33/80\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.4876 - binary_accuracy: 0.7872 - val_loss: 0.4921 - val_binary_accuracy: 0.7829\n",
            "Epoch 34/80\n",
            "15/15 [==============================] - 3s 200ms/step - loss: 0.5298 - binary_accuracy: 0.7386 - val_loss: 0.4830 - val_binary_accuracy: 0.7766\n",
            "Epoch 35/80\n",
            "15/15 [==============================] - 2s 162ms/step - loss: 0.4750 - binary_accuracy: 0.7789 - val_loss: 0.3842 - val_binary_accuracy: 0.8455\n",
            "Epoch 36/80\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.4549 - binary_accuracy: 0.7846 - val_loss: 0.3968 - val_binary_accuracy: 0.8225\n",
            "Epoch 37/80\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.4330 - binary_accuracy: 0.8055 - val_loss: 0.3240 - val_binary_accuracy: 0.8768\n",
            "Epoch 38/80\n",
            "15/15 [==============================] - 3s 181ms/step - loss: 0.3809 - binary_accuracy: 0.8395 - val_loss: 0.3685 - val_binary_accuracy: 0.8518\n",
            "Epoch 39/80\n",
            "15/15 [==============================] - 3s 208ms/step - loss: 0.3853 - binary_accuracy: 0.8395 - val_loss: 0.4117 - val_binary_accuracy: 0.8100\n",
            "Epoch 40/80\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.3503 - binary_accuracy: 0.8510 - val_loss: 0.3844 - val_binary_accuracy: 0.8288\n",
            "Epoch 41/80\n",
            "15/15 [==============================] - 4s 228ms/step - loss: 0.4242 - binary_accuracy: 0.8102 - val_loss: 0.2986 - val_binary_accuracy: 0.8831\n",
            "Epoch 42/80\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.3320 - binary_accuracy: 0.8651 - val_loss: 0.3847 - val_binary_accuracy: 0.8476\n",
            "Epoch 43/80\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.2873 - binary_accuracy: 0.8944 - val_loss: 0.2786 - val_binary_accuracy: 0.8956\n",
            "Epoch 44/80\n",
            "15/15 [==============================] - 3s 161ms/step - loss: 0.2991 - binary_accuracy: 0.8881 - val_loss: 0.2445 - val_binary_accuracy: 0.8977\n",
            "Epoch 45/80\n",
            "15/15 [==============================] - 2s 160ms/step - loss: 0.2532 - binary_accuracy: 0.9002 - val_loss: 0.2870 - val_binary_accuracy: 0.9040\n",
            "Epoch 46/80\n",
            "15/15 [==============================] - 3s 185ms/step - loss: 0.2570 - binary_accuracy: 0.9007 - val_loss: 0.2128 - val_binary_accuracy: 0.9144\n",
            "Epoch 47/80\n",
            "15/15 [==============================] - 2s 161ms/step - loss: 0.2213 - binary_accuracy: 0.9169 - val_loss: 0.3103 - val_binary_accuracy: 0.8935\n",
            "Epoch 48/80\n",
            "15/15 [==============================] - 3s 172ms/step - loss: 0.2467 - binary_accuracy: 0.9049 - val_loss: 0.2694 - val_binary_accuracy: 0.8998\n",
            "Epoch 49/80\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.2340 - binary_accuracy: 0.9049 - val_loss: 0.2065 - val_binary_accuracy: 0.9144\n",
            "Epoch 50/80\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.2644 - binary_accuracy: 0.8918 - val_loss: 0.2030 - val_binary_accuracy: 0.9144\n",
            "Epoch 51/80\n",
            "15/15 [==============================] - 3s 210ms/step - loss: 0.2183 - binary_accuracy: 0.9111 - val_loss: 0.1947 - val_binary_accuracy: 0.9311\n",
            "Epoch 52/80\n",
            "15/15 [==============================] - 2s 158ms/step - loss: 0.2393 - binary_accuracy: 0.9022 - val_loss: 0.2503 - val_binary_accuracy: 0.8956\n",
            "Epoch 53/80\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.2285 - binary_accuracy: 0.9064 - val_loss: 0.1935 - val_binary_accuracy: 0.9123\n",
            "Epoch 54/80\n",
            "15/15 [==============================] - 3s 175ms/step - loss: 0.1896 - binary_accuracy: 0.9284 - val_loss: 0.1537 - val_binary_accuracy: 0.9374\n",
            "Epoch 55/80\n",
            "15/15 [==============================] - 3s 172ms/step - loss: 0.1698 - binary_accuracy: 0.9383 - val_loss: 0.2482 - val_binary_accuracy: 0.9102\n",
            "Epoch 56/80\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.1799 - binary_accuracy: 0.9326 - val_loss: 0.1491 - val_binary_accuracy: 0.9395\n",
            "Epoch 57/80\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.2208 - binary_accuracy: 0.9232 - val_loss: 0.2065 - val_binary_accuracy: 0.9102\n",
            "Epoch 58/80\n",
            "15/15 [==============================] - 4s 306ms/step - loss: 0.1848 - binary_accuracy: 0.9279 - val_loss: 0.1876 - val_binary_accuracy: 0.9269\n",
            "Epoch 59/80\n",
            "15/15 [==============================] - 6s 370ms/step - loss: 0.1799 - binary_accuracy: 0.9300 - val_loss: 0.1384 - val_binary_accuracy: 0.9395\n",
            "Epoch 60/80\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1587 - binary_accuracy: 0.9425 - val_loss: 0.1810 - val_binary_accuracy: 0.9311\n",
            "Epoch 61/80\n",
            "15/15 [==============================] - 7s 421ms/step - loss: 0.1498 - binary_accuracy: 0.9399 - val_loss: 0.2286 - val_binary_accuracy: 0.9228\n",
            "Epoch 62/80\n",
            "15/15 [==============================] - 5s 343ms/step - loss: 0.1161 - binary_accuracy: 0.9571 - val_loss: 0.1360 - val_binary_accuracy: 0.9353\n",
            "Epoch 63/80\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.1400 - binary_accuracy: 0.9482 - val_loss: 0.1762 - val_binary_accuracy: 0.9395\n",
            "Epoch 64/80\n",
            "15/15 [==============================] - 3s 204ms/step - loss: 0.1389 - binary_accuracy: 0.9482 - val_loss: 0.1469 - val_binary_accuracy: 0.9395\n",
            "Epoch 65/80\n",
            "15/15 [==============================] - 2s 158ms/step - loss: 0.1324 - binary_accuracy: 0.9503 - val_loss: 0.1397 - val_binary_accuracy: 0.9395\n",
            "Epoch 66/80\n",
            "15/15 [==============================] - 3s 174ms/step - loss: 0.1614 - binary_accuracy: 0.9373 - val_loss: 0.1183 - val_binary_accuracy: 0.9499\n",
            "Epoch 67/80\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.1037 - binary_accuracy: 0.9603 - val_loss: 0.1265 - val_binary_accuracy: 0.9436\n",
            "Epoch 68/80\n",
            "15/15 [==============================] - 3s 209ms/step - loss: 0.1141 - binary_accuracy: 0.9603 - val_loss: 0.1187 - val_binary_accuracy: 0.9541\n",
            "Epoch 69/80\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.1053 - binary_accuracy: 0.9618 - val_loss: 0.0955 - val_binary_accuracy: 0.9624\n",
            "Epoch 70/80\n",
            "15/15 [==============================] - 2s 164ms/step - loss: 0.1379 - binary_accuracy: 0.9503 - val_loss: 0.1433 - val_binary_accuracy: 0.9374\n",
            "Epoch 71/80\n",
            "15/15 [==============================] - 2s 162ms/step - loss: 0.1449 - binary_accuracy: 0.9488 - val_loss: 0.3035 - val_binary_accuracy: 0.8956\n",
            "Epoch 72/80\n",
            "15/15 [==============================] - 3s 168ms/step - loss: 0.1147 - binary_accuracy: 0.9597 - val_loss: 0.0977 - val_binary_accuracy: 0.9666\n",
            "Epoch 73/80\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0923 - binary_accuracy: 0.9665 - val_loss: 0.1039 - val_binary_accuracy: 0.9541\n",
            "Epoch 74/80\n",
            "15/15 [==============================] - 3s 204ms/step - loss: 0.1306 - binary_accuracy: 0.9535 - val_loss: 0.1487 - val_binary_accuracy: 0.9311\n",
            "Epoch 75/80\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.0959 - binary_accuracy: 0.9624 - val_loss: 0.0950 - val_binary_accuracy: 0.9624\n",
            "Epoch 76/80\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.0876 - binary_accuracy: 0.9697 - val_loss: 0.1100 - val_binary_accuracy: 0.9541\n",
            "Epoch 77/80\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 0.1061 - binary_accuracy: 0.9629 - val_loss: 0.0826 - val_binary_accuracy: 0.9687\n",
            "Epoch 78/80\n",
            "15/15 [==============================] - 3s 171ms/step - loss: 0.1225 - binary_accuracy: 0.9519 - val_loss: 0.0873 - val_binary_accuracy: 0.9582\n",
            "Epoch 79/80\n",
            "15/15 [==============================] - 3s 181ms/step - loss: 0.0909 - binary_accuracy: 0.9697 - val_loss: 0.1144 - val_binary_accuracy: 0.9562\n",
            "Epoch 80/80\n",
            "15/15 [==============================] - 2s 141ms/step - loss: 0.0848 - binary_accuracy: 0.9692 - val_loss: 0.1228 - val_binary_accuracy: 0.9520\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1078 - binary_accuracy: 0.9648\n",
            "Test loss: 0.10784848034381866\n"
          ]
        }
      ],
      "source": [
        "# Model Compilation\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "#Model Training\n",
        "epochs = 80\n",
        "model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n",
        "\n",
        "# Model Evaluation\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test loss:', test_loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ieIqwQet4e2N"
      },
      "source": [
        "## Make predictions on the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFyQEp0JtcEd",
        "outputId": "224f84a3-a7c1-4863-acc2-51a63af038c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 1s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "test_predictions = model.predict(test_images)\n",
        "test_predictions = (test_predictions > 0.5).astype(int).flatten()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NKOsj-W64gms"
      },
      "source": [
        "## Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqtay4QmwEEo",
        "outputId": "015119f0-8f3e-4ffe-bfc6-e59c637b8c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.93      0.96       290\n",
            "           1       0.94      0.99      0.97       307\n",
            "\n",
            "    accuracy                           0.96       597\n",
            "   macro avg       0.97      0.96      0.96       597\n",
            "weighted avg       0.97      0.96      0.96       597\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_labels, test_predictions))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t4kAPL8Y4iLD"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wTVyTt9MxEi5",
        "outputId": "1245ad74-827d-45d1-8579-73f9ec245ef2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix\n",
        "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Create a heatmap plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3DCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "input_shape = (1,224, 224, 3)\n",
        "# Convert labels to binary representation (0 for flipped, 1 for noflipped)\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "val_labels = label_encoder.transform(val_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = load_img(image_path, target_size=input_shape)\n",
        "    image = img_to_array(image)\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Load and preprocess the training, validation, and test images\n",
        "train_images = np.array([preprocess_image(image_path) for image_path in train_images])\n",
        "val_images = np.array([preprocess_image(image_path) for image_path in val_images])\n",
        "test_images = np.array([preprocess_image(image_path) for image_path in test_images])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    #horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node 'sequential_17/dense_37/Relu' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1919, in _run_once\n      handle._run()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\mbajd\\AppData\\Local\\Temp\\ipykernel_15252\\1411515583.py\", line 95, in <module>\n      model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_17/dense_37/Relu'\nMatrix size-incompatible: In[0]: [32,0], In[1]: [952560,128]\n\t [[{{node sequential_17/dense_37/Relu}}]] [Op:__inference_train_function_16798]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m# Model Training\u001b[39;00m\n\u001b[0;32m     94\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m---> 95\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49m(val_images, val_labels))\n\u001b[0;32m     97\u001b[0m \u001b[39m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     98\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_images, test_labels)\n",
            "File \u001b[1;32mc:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_17/dense_37/Relu' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1919, in _run_once\n      handle._run()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\mbajd\\AppData\\Local\\Temp\\ipykernel_15252\\1411515583.py\", line 95, in <module>\n      model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_17/dense_37/Relu'\nMatrix size-incompatible: In[0]: [32,0], In[1]: [952560,128]\n\t [[{{node sequential_17/dense_37/Relu}}]] [Op:__inference_train_function_16798]"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv3D, MaxPool3D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Load the image paths from the 'flipped' and 'noflipped' subfolders\n",
        "flipped_images = glob.glob(flipped_dir + '/*.jpg')\n",
        "noflipped_images = glob.glob(noflipped_dir + '/*.jpg')\n",
        "\n",
        "# Assuming you have your labels as 'flipped' and 'noflipped'\n",
        "flipped_labels = ['flip'] * len(flipped_images)\n",
        "noflipped_labels = ['noflip'] * len(noflipped_images)\n",
        "\n",
        "# Concatenate the flipped and noflipped images and labels\n",
        "images = flipped_images + noflipped_images\n",
        "labels = flipped_labels + noflipped_labels\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the test images and labels\n",
        "test_flipped_images = glob.glob(test_dir + '/flip/*.jpg')\n",
        "test_noflipped_images = glob.glob(test_dir + '/notflip/*.jpg')\n",
        "\n",
        "test_images = test_flipped_images + test_noflipped_images\n",
        "test_labels = ['flip'] * len(test_flipped_images) + ['noflip'] * len(test_noflipped_images)\n",
        "\n",
        "input_shape = (32, 128, 128)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "val_labels = label_encoder.transform(val_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels = to_categorical(val_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess_image(image_path):\n",
        "    image = load_img(image_path, target_size=(input_shape[0], input_shape[1], input_shape[2]))\n",
        "    image = img_to_array(image)\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Load and preprocess the training, validation, and test images\n",
        "train_images = np.array([preprocess_image(image_path) for image_path in train_images])\n",
        "val_images = np.array([preprocess_image(image_path) for image_path in val_images])\n",
        "test_images = np.array([preprocess_image(image_path) for image_path in test_images])\n",
        "\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential([\n",
        "    Conv3D(16, kernel_size=(3, 3, 3), padding='valid', activation='relu', input_shape=(32,128,128,1)),\n",
        "    #Conv3D(16, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "    #Conv3D(32, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "    MaxPool3D(pool_size=(2, 2, 2)),\n",
        "    BatchNormalization(),\n",
        "    #Conv3D(32, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "    #Conv3D(32, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "    #MaxPool3D(pool_size=(2, 2, 2)),\n",
        "    #BatchNormalization(),\n",
        "    Flatten(),\n",
        "    #Dense(2048, activation='relu'),\n",
        "    #Dropout(0.6),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.6),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Model Compilation\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "epochs = 20\n",
        "model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n",
        "\n",
        "# Model Evaluation\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "model_2 = Sequential([\n",
        "  Conv3D(16, kernel_size=(3, 3, 3), padding='valid', activation='relu', input_shape=(128, 224, 224, 3), data_format='channels_first'),\n",
        "  Conv3D(16, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "  Conv3D(32, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "\n",
        "  MaxPool3D(pool_size=(2, 2, 2)),\n",
        "  BatchNormalization(),\n",
        "\n",
        "  Conv3D(32, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "  Conv3D(32, kernel_size=(3, 3, 3), padding='valid', activation='relu'),\n",
        "\n",
        "\n",
        "  MaxPool3D(pool_size=(2, 2, 2)),\n",
        "  BatchNormalization(),\n",
        "\n",
        "\n",
        "  Flatten(),\n",
        "\n",
        "  #GlobalAveragePooling3D(),\n",
        "  Dense(2048, activation='relu'),\n",
        "  Dropout(0.6),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dropout(0.6),\n",
        "  Dense(1, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1919, in _run_once\n      handle._run()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\mbajd\\AppData\\Local\\Temp\\ipykernel_25440\\930318437.py\", line 9, in <module>\n      model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\accuracy_metrics.py\", line 395, in binary_accuracy\n      metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 934, in binary_matches\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nIncompatible shapes: [128,32,32,3] vs. [128]\n\t [[{{node Equal}}]] [Op:__inference_train_function_52021]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[102], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m#Model Training\u001b[39;00m\n\u001b[0;32m      8\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49m(val_images, val_labels))\n\u001b[0;32m     11\u001b[0m \u001b[39m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_images, test_labels)\n",
            "File \u001b[1;32mc:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1919, in _run_once\n      handle._run()\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\mbajd\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\mbajd\\AppData\\Local\\Temp\\ipykernel_25440\\930318437.py\", line 9, in <module>\n      model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\metrics\\accuracy_metrics.py\", line 395, in binary_accuracy\n      metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"c:\\Users\\mbajd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 934, in binary_matches\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nIncompatible shapes: [128,32,32,3] vs. [128]\n\t [[{{node Equal}}]] [Op:__inference_train_function_52021]"
          ]
        }
      ],
      "source": [
        "# Model Compilation\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "#Model Training\n",
        "epochs = 20\n",
        "model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n",
        "\n",
        "# Model Evaluation\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test loss:', test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
