{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrcl3/kLfCelvFM1n2urrn/blob/main/2DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3skq5edU4P"
      },
      "source": [
        "# 2D CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb2uSyKh24DS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation, Rescaling, BatchNormalization, Conv3D, MaxPool3D, Dropout\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow.keras as keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YqnkQaO3T5k"
      },
      "source": [
        "## Declaring the repositories with images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5H1KmZ_27Mk"
      },
      "outputs": [],
      "source": [
        "# Assuming your image folder is called 'dataset' and contains two subfolders: 'flipped' and 'noflipped'\n",
        "flipped_dir = '/content/drive/MyDrive/MonReader/images (1)/images/training/flip'\n",
        "noflipped_dir = '/content/drive/MyDrive/MonReader/images (1)/images/training/notflip'\n",
        "test_dir = '/content/drive/MyDrive/MonReader/images (1)/images/testing/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMcrfp8a3QVj"
      },
      "source": [
        "## Loading the images for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRiKu44J2961"
      },
      "outputs": [],
      "source": [
        "# Load the image paths from the 'flipped' and 'noflipped' subfolders\n",
        "flipped_images = glob.glob(flipped_dir + '/*.jpg')  # Assuming your images have the .jpg extension\n",
        "noflipped_images = glob.glob(noflipped_dir + '/*.jpg')\n",
        "\n",
        "# Assuming you have your labels as 'flipped' and 'noflipped'\n",
        "flipped_labels = ['flip'] * len(flipped_images)\n",
        "noflipped_labels = ['noflip'] * len(noflipped_images)\n",
        "\n",
        "# Concatenate the flipped and noflipped images and labels\n",
        "images = flipped_images + noflipped_images\n",
        "labels = flipped_labels + noflipped_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6rP6qiF3beW"
      },
      "source": [
        "## Organizing train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZzfJOjc3ZbS"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the test images and labels\n",
        "test_flipped_images = glob.glob(test_dir + '/flip/*.jpg')\n",
        "test_noflipped_images = glob.glob(test_dir + '/notflip/*.jpg')\n",
        "\n",
        "test_images = test_flipped_images + test_noflipped_images\n",
        "test_labels = ['flip'] * len(test_flipped_images) + ['noflip'] * len(test_noflipped_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-eBdwor3gCq"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iMFPPxr4BE3"
      },
      "outputs": [],
      "source": [
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Convert labels to binary representation (0 for flipped, 1 for noflipped)\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "val_labels = label_encoder.transform(val_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, input_shape[:2])\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Load and preprocess the training, validation, and test images\n",
        "train_images = np.array([preprocess_image(image_path) for image_path in train_images])\n",
        "val_images = np.array([preprocess_image(image_path) for image_path in val_images])\n",
        "test_images = np.array([preprocess_image(image_path) for image_path in test_images])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu8Tuerg4Ej_"
      },
      "source": [
        "## ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOchBBnG4C5Q"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    #horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMrXEEt-4I8O"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ehx_uxN4OCN"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.MaxPool2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output neuron for binary classification\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mJkK_RD4Pgo"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdEQN9bo4Rho",
        "outputId": "66e85e79-79fe-465e-dfbd-7708ccb36850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 15, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 512)               66048     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 323,649\n",
            "Trainable params: 323,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YM0xSXC4Vyw"
      },
      "source": [
        "## Model compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQkEo0JRfjNB",
        "outputId": "a216daf9-0516-426a-cd30-5ec4965e92d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "15/15 [==============================] - 8s 468ms/step - loss: 0.6957 - binary_accuracy: 0.4835 - val_loss: 0.6917 - val_binary_accuracy: 0.5240\n",
            "Epoch 2/80\n",
            "15/15 [==============================] - 4s 240ms/step - loss: 0.6929 - binary_accuracy: 0.5044 - val_loss: 0.6907 - val_binary_accuracy: 0.5240\n",
            "Epoch 3/80\n",
            "15/15 [==============================] - 4s 285ms/step - loss: 0.6926 - binary_accuracy: 0.5039 - val_loss: 0.6909 - val_binary_accuracy: 0.5240\n",
            "Epoch 4/80\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.6927 - binary_accuracy: 0.5081 - val_loss: 0.6909 - val_binary_accuracy: 0.5240\n",
            "Epoch 5/80\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.6919 - binary_accuracy: 0.5196 - val_loss: 0.6907 - val_binary_accuracy: 0.5240\n",
            "Epoch 6/80\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.6930 - binary_accuracy: 0.5050 - val_loss: 0.6905 - val_binary_accuracy: 0.5240\n",
            "Epoch 7/80\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.6911 - binary_accuracy: 0.5280 - val_loss: 0.6902 - val_binary_accuracy: 0.5240\n",
            "Epoch 8/80\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.6916 - binary_accuracy: 0.5227 - val_loss: 0.6894 - val_binary_accuracy: 0.5240\n",
            "Epoch 9/80\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.6908 - binary_accuracy: 0.5363 - val_loss: 0.6894 - val_binary_accuracy: 0.5219\n",
            "Epoch 10/80\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.6904 - binary_accuracy: 0.5348 - val_loss: 0.6880 - val_binary_accuracy: 0.5240\n",
            "Epoch 11/80\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.6897 - binary_accuracy: 0.5342 - val_loss: 0.6869 - val_binary_accuracy: 0.5240\n",
            "Epoch 12/80\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.6900 - binary_accuracy: 0.5290 - val_loss: 0.6866 - val_binary_accuracy: 0.5344\n",
            "Epoch 13/80\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.6888 - binary_accuracy: 0.5557 - val_loss: 0.6847 - val_binary_accuracy: 0.5616\n",
            "Epoch 14/80\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.6874 - binary_accuracy: 0.5630 - val_loss: 0.6830 - val_binary_accuracy: 0.5658\n",
            "Epoch 15/80\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.6880 - binary_accuracy: 0.5421 - val_loss: 0.6810 - val_binary_accuracy: 0.5428\n",
            "Epoch 16/80\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.6855 - binary_accuracy: 0.5619 - val_loss: 0.6786 - val_binary_accuracy: 0.6013\n",
            "Epoch 17/80\n",
            "15/15 [==============================] - 6s 368ms/step - loss: 0.6829 - binary_accuracy: 0.5907 - val_loss: 0.6745 - val_binary_accuracy: 0.5908\n",
            "Epoch 18/80\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.6817 - binary_accuracy: 0.5886 - val_loss: 0.6687 - val_binary_accuracy: 0.6159\n",
            "Epoch 19/80\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.6768 - binary_accuracy: 0.6079 - val_loss: 0.6635 - val_binary_accuracy: 0.7265\n",
            "Epoch 20/80\n",
            "15/15 [==============================] - 5s 288ms/step - loss: 0.6732 - binary_accuracy: 0.6231 - val_loss: 0.6531 - val_binary_accuracy: 0.7411\n",
            "Epoch 21/80\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.6589 - binary_accuracy: 0.6524 - val_loss: 0.6454 - val_binary_accuracy: 0.6117\n",
            "Epoch 22/80\n",
            "15/15 [==============================] - 4s 263ms/step - loss: 0.6520 - binary_accuracy: 0.6430 - val_loss: 0.6212 - val_binary_accuracy: 0.7370\n",
            "Epoch 23/80\n",
            "15/15 [==============================] - 7s 433ms/step - loss: 0.6346 - binary_accuracy: 0.6560 - val_loss: 0.5899 - val_binary_accuracy: 0.7537\n",
            "Epoch 24/80\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.6198 - binary_accuracy: 0.6654 - val_loss: 0.5819 - val_binary_accuracy: 0.6848\n",
            "Epoch 25/80\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.5964 - binary_accuracy: 0.6947 - val_loss: 0.5737 - val_binary_accuracy: 0.7015\n",
            "Epoch 26/80\n",
            "15/15 [==============================] - 6s 410ms/step - loss: 0.5732 - binary_accuracy: 0.7156 - val_loss: 0.5279 - val_binary_accuracy: 0.7265\n",
            "Epoch 27/80\n",
            "15/15 [==============================] - 5s 291ms/step - loss: 0.5578 - binary_accuracy: 0.7266 - val_loss: 0.5056 - val_binary_accuracy: 0.7641\n",
            "Epoch 28/80\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.5436 - binary_accuracy: 0.7344 - val_loss: 0.5595 - val_binary_accuracy: 0.7098\n",
            "Epoch 29/80\n",
            "15/15 [==============================] - 4s 278ms/step - loss: 0.5175 - binary_accuracy: 0.7606 - val_loss: 0.4558 - val_binary_accuracy: 0.8038\n",
            "Epoch 30/80\n",
            "15/15 [==============================] - 7s 427ms/step - loss: 0.4835 - binary_accuracy: 0.7784 - val_loss: 0.4206 - val_binary_accuracy: 0.8330\n",
            "Epoch 31/80\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.4530 - binary_accuracy: 0.8040 - val_loss: 0.4925 - val_binary_accuracy: 0.7599\n",
            "Epoch 32/80\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.4480 - binary_accuracy: 0.7961 - val_loss: 0.3802 - val_binary_accuracy: 0.8163\n",
            "Epoch 33/80\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.3937 - binary_accuracy: 0.8301 - val_loss: 0.3270 - val_binary_accuracy: 0.8643\n",
            "Epoch 34/80\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.3977 - binary_accuracy: 0.8312 - val_loss: 0.3876 - val_binary_accuracy: 0.8121\n",
            "Epoch 35/80\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.3566 - binary_accuracy: 0.8474 - val_loss: 0.2754 - val_binary_accuracy: 0.8914\n",
            "Epoch 36/80\n",
            "15/15 [==============================] - 6s 417ms/step - loss: 0.3533 - binary_accuracy: 0.8510 - val_loss: 0.3939 - val_binary_accuracy: 0.8142\n",
            "Epoch 37/80\n",
            "15/15 [==============================] - 4s 239ms/step - loss: 0.3911 - binary_accuracy: 0.8348 - val_loss: 0.3102 - val_binary_accuracy: 0.8768\n",
            "Epoch 38/80\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.4351 - binary_accuracy: 0.7987 - val_loss: 0.2874 - val_binary_accuracy: 0.8914\n",
            "Epoch 39/80\n",
            "15/15 [==============================] - 5s 306ms/step - loss: 0.3856 - binary_accuracy: 0.8265 - val_loss: 0.2612 - val_binary_accuracy: 0.9019\n",
            "Epoch 40/80\n",
            "15/15 [==============================] - 6s 379ms/step - loss: 0.3510 - binary_accuracy: 0.8437 - val_loss: 0.4457 - val_binary_accuracy: 0.7850\n",
            "Epoch 41/80\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.3278 - binary_accuracy: 0.8636 - val_loss: 0.2338 - val_binary_accuracy: 0.9019\n",
            "Epoch 42/80\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.3308 - binary_accuracy: 0.8688 - val_loss: 0.3380 - val_binary_accuracy: 0.8434\n",
            "Epoch 43/80\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.3203 - binary_accuracy: 0.8651 - val_loss: 0.2646 - val_binary_accuracy: 0.9144\n",
            "Epoch 44/80\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.3146 - binary_accuracy: 0.8657 - val_loss: 0.2272 - val_binary_accuracy: 0.9123\n",
            "Epoch 45/80\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.2459 - binary_accuracy: 0.9028 - val_loss: 0.1954 - val_binary_accuracy: 0.9290\n",
            "Epoch 46/80\n",
            "15/15 [==============================] - 4s 238ms/step - loss: 0.2503 - binary_accuracy: 0.9054 - val_loss: 0.1802 - val_binary_accuracy: 0.9332\n",
            "Epoch 47/80\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.2116 - binary_accuracy: 0.9174 - val_loss: 0.1849 - val_binary_accuracy: 0.9311\n",
            "Epoch 48/80\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.2150 - binary_accuracy: 0.9221 - val_loss: 0.1976 - val_binary_accuracy: 0.9269\n",
            "Epoch 49/80\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.2515 - binary_accuracy: 0.8981 - val_loss: 0.1655 - val_binary_accuracy: 0.9395\n",
            "Epoch 50/80\n",
            "15/15 [==============================] - 4s 296ms/step - loss: 0.2085 - binary_accuracy: 0.9205 - val_loss: 0.1815 - val_binary_accuracy: 0.9290\n",
            "Epoch 51/80\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.1897 - binary_accuracy: 0.9268 - val_loss: 0.1797 - val_binary_accuracy: 0.9311\n",
            "Epoch 52/80\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.1730 - binary_accuracy: 0.9362 - val_loss: 0.2082 - val_binary_accuracy: 0.9269\n",
            "Epoch 53/80\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.2011 - binary_accuracy: 0.9195 - val_loss: 0.1465 - val_binary_accuracy: 0.9436\n",
            "Epoch 54/80\n",
            "15/15 [==============================] - 7s 427ms/step - loss: 0.1832 - binary_accuracy: 0.9273 - val_loss: 0.1322 - val_binary_accuracy: 0.9499\n",
            "Epoch 55/80\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.1715 - binary_accuracy: 0.9378 - val_loss: 0.1728 - val_binary_accuracy: 0.9415\n",
            "Epoch 56/80\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.1986 - binary_accuracy: 0.9263 - val_loss: 0.1374 - val_binary_accuracy: 0.9499\n",
            "Epoch 57/80\n",
            "15/15 [==============================] - 6s 392ms/step - loss: 0.1550 - binary_accuracy: 0.9425 - val_loss: 0.1170 - val_binary_accuracy: 0.9562\n",
            "Epoch 58/80\n",
            "15/15 [==============================] - 5s 304ms/step - loss: 0.2021 - binary_accuracy: 0.9195 - val_loss: 0.1233 - val_binary_accuracy: 0.9520\n",
            "Epoch 59/80\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.1597 - binary_accuracy: 0.9441 - val_loss: 0.1146 - val_binary_accuracy: 0.9582\n",
            "Epoch 60/80\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.1426 - binary_accuracy: 0.9462 - val_loss: 0.1446 - val_binary_accuracy: 0.9436\n",
            "Epoch 61/80\n",
            "15/15 [==============================] - 6s 368ms/step - loss: 0.1956 - binary_accuracy: 0.9216 - val_loss: 0.1420 - val_binary_accuracy: 0.9374\n",
            "Epoch 62/80\n",
            "15/15 [==============================] - 4s 238ms/step - loss: 0.1560 - binary_accuracy: 0.9420 - val_loss: 0.1266 - val_binary_accuracy: 0.9478\n",
            "Epoch 63/80\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.1271 - binary_accuracy: 0.9524 - val_loss: 0.0772 - val_binary_accuracy: 0.9708\n",
            "Epoch 64/80\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.1234 - binary_accuracy: 0.9566 - val_loss: 0.0922 - val_binary_accuracy: 0.9666\n",
            "Epoch 65/80\n",
            "15/15 [==============================] - 4s 236ms/step - loss: 0.1142 - binary_accuracy: 0.9577 - val_loss: 0.0975 - val_binary_accuracy: 0.9541\n",
            "Epoch 66/80\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.1589 - binary_accuracy: 0.9404 - val_loss: 0.0915 - val_binary_accuracy: 0.9708\n",
            "Epoch 67/80\n",
            "15/15 [==============================] - 6s 379ms/step - loss: 0.1524 - binary_accuracy: 0.9420 - val_loss: 0.1675 - val_binary_accuracy: 0.9436\n",
            "Epoch 68/80\n",
            "15/15 [==============================] - 5s 315ms/step - loss: 0.1352 - binary_accuracy: 0.9503 - val_loss: 0.1183 - val_binary_accuracy: 0.9582\n",
            "Epoch 69/80\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.0973 - binary_accuracy: 0.9660 - val_loss: 0.0728 - val_binary_accuracy: 0.9708\n",
            "Epoch 70/80\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.1261 - binary_accuracy: 0.9488 - val_loss: 0.1568 - val_binary_accuracy: 0.9478\n",
            "Epoch 71/80\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 0.1824 - binary_accuracy: 0.9279 - val_loss: 0.1693 - val_binary_accuracy: 0.9311\n",
            "Epoch 72/80\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.1612 - binary_accuracy: 0.9336 - val_loss: 0.0875 - val_binary_accuracy: 0.9687\n",
            "Epoch 73/80\n",
            "15/15 [==============================] - 4s 264ms/step - loss: 0.1507 - binary_accuracy: 0.9378 - val_loss: 0.1026 - val_binary_accuracy: 0.9603\n",
            "Epoch 74/80\n",
            "15/15 [==============================] - 6s 420ms/step - loss: 0.1412 - binary_accuracy: 0.9441 - val_loss: 0.0722 - val_binary_accuracy: 0.9791\n",
            "Epoch 75/80\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.1084 - binary_accuracy: 0.9671 - val_loss: 0.0987 - val_binary_accuracy: 0.9603\n",
            "Epoch 76/80\n",
            "15/15 [==============================] - 4s 242ms/step - loss: 0.0871 - binary_accuracy: 0.9686 - val_loss: 0.0806 - val_binary_accuracy: 0.9687\n",
            "Epoch 77/80\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.1034 - binary_accuracy: 0.9613 - val_loss: 0.0788 - val_binary_accuracy: 0.9729\n",
            "Epoch 78/80\n",
            "15/15 [==============================] - 5s 308ms/step - loss: 0.1104 - binary_accuracy: 0.9645 - val_loss: 0.0881 - val_binary_accuracy: 0.9624\n",
            "Epoch 79/80\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.1164 - binary_accuracy: 0.9577 - val_loss: 0.0845 - val_binary_accuracy: 0.9687\n",
            "Epoch 80/80\n",
            "15/15 [==============================] - 4s 284ms/step - loss: 0.0855 - binary_accuracy: 0.9723 - val_loss: 0.0988 - val_binary_accuracy: 0.9645\n",
            "19/19 [==============================] - 1s 27ms/step - loss: 0.1143 - binary_accuracy: 0.9648\n",
            "Test loss: 0.11430122703313828\n"
          ]
        }
      ],
      "source": [
        "# Model Compilation\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "#Model Training\n",
        "epochs = 80\n",
        "model.fit(train_generator, epochs=epochs, validation_data=(val_images, val_labels))\n",
        "\n",
        "# Model Evaluation\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test loss:', test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieIqwQet4e2N"
      },
      "source": [
        "## Make predictions on the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFyQEp0JtcEd",
        "outputId": "224f84a3-a7c1-4863-acc2-51a63af038c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 1s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "test_predictions = model.predict(test_images)\n",
        "test_predictions = (test_predictions > 0.5).astype(int).flatten()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKOsj-W64gms"
      },
      "source": [
        "## Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqtay4QmwEEo",
        "outputId": "015119f0-8f3e-4ffe-bfc6-e59c637b8c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96       290\n",
            "           1       0.94      1.00      0.97       307\n",
            "\n",
            "    accuracy                           0.96       597\n",
            "   macro avg       0.97      0.96      0.96       597\n",
            "weighted avg       0.97      0.96      0.96       597\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_labels, test_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4kAPL8Y4iLD"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wTVyTt9MxEi5",
        "outputId": "1245ad74-827d-45d1-8579-73f9ec245ef2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute confusion matrix\n",
        "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "# Create a heatmap plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtJzgaY7Ey4h"
      },
      "source": [
        "# Vision Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYcwVtl5E1aT",
        "outputId": "18d86ba4-3ecb-4ff6-e629-9fd49dc4823b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patchify in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoOU3dXWEf9K"
      },
      "outputs": [],
      "source": [
        "from patchify import patchify\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrS62BLGE47w"
      },
      "source": [
        "## Hyperparemeters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W851a3YXE3Fq"
      },
      "outputs": [],
      "source": [
        "hp = {}\n",
        "hp['image_size'] = 200\n",
        "hp['num_channels'] = 3\n",
        "hp['patch_size'] = 25\n",
        "hp['num_patches'] = (hp['image_size']**2) // (hp['patch_size']**2)\n",
        "hp['flat_patches_shape'] = (hp['num_patches'], hp['patch_size']*hp['patch_size']*hp['num_channels'])\n",
        "\n",
        "hp['batch_size'] = 32\n",
        "hp['lr'] = 1e-4\n",
        "hp['num_epochs'] = 50\n",
        "hp['num_classes'] = 2\n",
        "hp['class_names'] = ['flip', 'notflip']\n",
        "\n",
        "hp[\"num_layers\"] = 12\n",
        "hp[\"hidden_dim\"] = 768\n",
        "hp[\"mlp_dim\"] = 3072\n",
        "hp[\"num_heads\"] = 12\n",
        "hp[\"dropout_rate\"] = 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-2iCV7rGKig"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G6njLUmGtds"
      },
      "outputs": [],
      "source": [
        "def load_data(path, split=0.2):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "    split_size = int(len(images) * split)\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "    return train_x, valid_x, test_x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data(path):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "    test_x2 = images\n",
        "    return test_x2\n",
        "\n"
      ],
      "metadata": {
        "id": "7ocwAlvi8gKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qIkpIrdJnMQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.stateless_random_ops import split\n",
        "def process_image_label(path):\n",
        "  path = path.decode()\n",
        "  \"\"\" reading images \"\"\"\n",
        "  image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "  image = cv2.resize(image, (hp['image_size'], hp['image_size']))\n",
        "  #image = image/255.0\n",
        "  #print(image.shape)\n",
        "  \"\"\" Preprocessing to patches\"\"\"\n",
        "  patch_shape = (hp['patch_size'], hp['patch_size'], hp['num_channels'])\n",
        "  patches = patchify(image, patch_shape, hp['patch_size'])\n",
        "  patches = np.reshape(patches, (64,25,25,3))\n",
        "  \"\"\" Printing the patches\"\"\"\n",
        "  \"\"\"\n",
        "  for i in range(64):\n",
        "    cv2.imwrite(f\"/content/drive/MyDrive/MonReader/files/{i}.png\", patches[i])\n",
        "  print(patches.shape)\n",
        "  \"\"\"\n",
        "  patches = np.reshape(patches, hp['flat_patches_shape'])\n",
        "  patches = patches.astype(np.float32)\n",
        "\n",
        "\n",
        "  \"\"\" Label \"\"\"\n",
        "  class_name = path.split('/')[-2]\n",
        "  #print(class_name)\n",
        "  class_idx = hp['class_names'].index(class_name)\n",
        "  class_idx = np.array(class_idx, dtype=np.int32)\n",
        "  #print(class_idx)\n",
        "\n",
        "  return patches, class_idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ZA0ZgJNrpS"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "  patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
        "  labels = tf.one_hot(labels, hp['num_classes'])\n",
        "\n",
        "  patches.set_shape(hp['flat_patches_shape'])\n",
        "  labels.set_shape(hp['num_classes'])\n",
        "\n",
        "  return patches, labels\n",
        "\n",
        "def tf_dataset(images, batch=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
        "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azfAP5IPOdlB"
      },
      "outputs": [],
      "source": [
        "def tf_dataset(images, batch=32):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((images))\n",
        "  ds = ds.map(parse).batch(batch).prefetch(8)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTbGew-OGAKt"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  \"\"\"Seeding\"\"\"\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  create_dir(\"/content/drive/MyDrive/MonReader/files\")\n",
        "  dataset_path = \"/content/drive/MyDrive/MonReader/images (1)/images/training\"\n",
        "  model_path = os.path.join(\"files\", \"model.h5\")\n",
        "  csv_path = os.path.join(\"files\", \"log.csv\")\n",
        "  \"\"\" Dataset training \"\"\"\n",
        "  train_x, valid_x, test_x = load_data(dataset_path)\n",
        "\n",
        "  train_ds = tf_dataset(train_x, batch=hp['batch_size'])\n",
        "  valid_ds = tf_dataset(valid_x, batch=hp['batch_size'])\n",
        "  test_x = load_test_data('/content/drive/MyDrive/MonReader/images (1)/images/testing')\n",
        "  test_ds = tf_dataset(test_x, batch=hp['batch_size'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "J8tWBl65C0gS",
        "outputId": "f407a872-bc1e-47d3-c7e0-9f419efe925b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ddabaae5c20e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute 'labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CYcsrRQPyg5"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYmyYidjH4xi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZEk4sDIQSIh"
      },
      "outputs": [],
      "source": [
        "class ClassToken(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
        "            trainable = True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        hidden_dim = self.w.shape[-1]\n",
        "\n",
        "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
        "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
        "        return cls\n",
        "\n",
        "def mlp(x, cf):\n",
        "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    x = Dense(cf[\"hidden_dim\"])(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    return x\n",
        "\n",
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MultiHeadAttention(\n",
        "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
        "    )(x, x)\n",
        "    x = Add()([x, skip_1])\n",
        "\n",
        "    skip_2 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = Add()([x, skip_2])\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BRF8iJIQLJm"
      },
      "outputs": [],
      "source": [
        "def ViT(cf):\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
        "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
        "\n",
        "    \"\"\" Patch + Position Embeddings \"\"\"\n",
        "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
        "\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
        "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
        "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
        "\n",
        "    \"\"\" Adding Class Token \"\"\"\n",
        "    token = ClassToken()(embed)\n",
        "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
        "\n",
        "    for _ in range(cf[\"num_layers\"]):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "    \"\"\" Classification Head \"\"\"\n",
        "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
        "    x = x[:, 0, :]\n",
        "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsI-_7KOQI_m",
        "outputId": "51a1bd1f-83c3-4d2a-cc67-981677301780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 3072)]  0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256, 768)     2360064     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 256, 768)    0           ['dense[0][0]']                  \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " class_token (ClassToken)       (None, 1, 768)       768         ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 257, 768)     0           ['class_token[0][0]',            \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 257, 768)    1536        ['concatenate[0][0]']            \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 257, 768)    28339968    ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 257, 768)     0           ['multi_head_attention[0][0]',   \n",
            "                                                                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 257, 768)    1536        ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 257, 3072)    2362368     ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 257, 3072)    0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 257, 768)     2360064     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 257, 768)     0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 257, 768)     0           ['dropout_1[0][0]',              \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 257, 768)    1536        ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 257, 768)     0           ['multi_head_attention_1[0][0]', \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 257, 768)    1536        ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 257, 3072)    2362368     ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 257, 3072)    0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 257, 768)     2360064     ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 257, 768)     0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 257, 768)     0           ['dropout_3[0][0]',              \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 257, 768)    1536        ['add_3[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 257, 768)     0           ['multi_head_attention_2[0][0]', \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 257, 768)    1536        ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 257, 3072)    2362368     ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 257, 3072)    0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 257, 768)     2360064     ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 257, 768)     0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 257, 768)     0           ['dropout_5[0][0]',              \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 257, 768)    1536        ['add_5[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 257, 768)     0           ['multi_head_attention_3[0][0]', \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 257, 768)    1536        ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 257, 3072)    2362368     ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 257, 3072)    0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 257, 768)     2360064     ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 257, 768)     0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 257, 768)     0           ['dropout_7[0][0]',              \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 257, 768)    1536        ['add_7[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_8[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 257, 768)     0           ['multi_head_attention_4[0][0]', \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 257, 768)    1536        ['add_8[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 257, 3072)    2362368     ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 257, 3072)    0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 257, 768)     2360064     ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 257, 768)     0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 257, 768)     0           ['dropout_9[0][0]',              \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 257, 768)    1536        ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_10[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 257, 768)     0           ['multi_head_attention_5[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 257, 768)    1536        ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 257, 3072)    0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 257, 768)     2360064     ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 257, 768)     0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 257, 768)     0           ['dropout_11[0][0]',             \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 257, 768)    1536        ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_12[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 257, 768)     0           ['multi_head_attention_6[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 257, 768)    1536        ['add_12[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 257, 3072)    0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 257, 768)     2360064     ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 257, 768)     0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 257, 768)     0           ['dropout_13[0][0]',             \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 257, 768)    1536        ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_14[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 257, 768)     0           ['multi_head_attention_7[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 257, 768)    1536        ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 257, 3072)    0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 257, 768)     2360064     ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 257, 768)     0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 257, 768)     0           ['dropout_15[0][0]',             \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 257, 768)    1536        ['add_15[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_16[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 257, 768)     0           ['multi_head_attention_8[0][0]', \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 257, 768)    1536        ['add_16[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 257, 3072)    0           ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 257, 768)     2360064     ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 257, 768)     0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 257, 768)     0           ['dropout_17[0][0]',             \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_18 (LayerN  (None, 257, 768)    1536        ['add_17[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (MultiH  (None, 257, 768)    28339968    ['layer_normalization_18[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 257, 768)     0           ['multi_head_attention_9[0][0]', \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_19 (LayerN  (None, 257, 768)    1536        ['add_18[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 257, 3072)    0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 257, 768)     2360064     ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 257, 768)     0           ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 257, 768)     0           ['dropout_19[0][0]',             \n",
            "                                                                  'add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_20 (LayerN  (None, 257, 768)    1536        ['add_19[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (Multi  (None, 257, 768)    28339968    ['layer_normalization_20[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 257, 768)     0           ['multi_head_attention_10[0][0]',\n",
            "                                                                  'add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_21 (LayerN  (None, 257, 768)    1536        ['add_20[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 257, 3072)    0           ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 257, 768)     2360064     ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 257, 768)     0           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 257, 768)     0           ['dropout_21[0][0]',             \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_22 (LayerN  (None, 257, 768)    1536        ['add_21[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (Multi  (None, 257, 768)    28339968    ['layer_normalization_22[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 257, 768)     0           ['multi_head_attention_11[0][0]',\n",
            "                                                                  'add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_23 (LayerN  (None, 257, 768)    1536        ['add_22[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 257, 3072)    2362368     ['layer_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 257, 3072)    0           ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 257, 768)     2360064     ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 257, 768)     0           ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 257, 768)     0           ['dropout_23[0][0]',             \n",
            "                                                                  'add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_24 (LayerN  (None, 257, 768)    1536        ['add_23[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['layer_normalization_24[0][0]'] \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 5)            3845        ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 399,151,877\n",
            "Trainable params: 399,151,877\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    config = {}\n",
        "    config[\"num_layers\"] = 12\n",
        "    config[\"hidden_dim\"] = 768\n",
        "    config[\"mlp_dim\"] = 3072\n",
        "    config[\"num_heads\"] = 12\n",
        "    config[\"dropout_rate\"] = 0.1\n",
        "    config[\"num_patches\"] = 256\n",
        "    config[\"patch_size\"] = 32\n",
        "    config[\"num_channels\"] = 3\n",
        "    config[\"num_classes\"] = 5\n",
        "\n",
        "    model = ViT(config)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSpf91ulQabG"
      },
      "outputs": [],
      "source": [
        "model = ViT(hp)\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(hp['lr'], clipvalue=1.0),\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-09SdxnXQ0Mc",
        "outputId": "faf6a3a4-c6c9-41cb-fc86-b465aad3fdde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2330 - acc: 0.4868\n",
            "Epoch 1: val_loss improved from inf to 0.82684, saving model to files/model.h5\n",
            "45/45 [==============================] - 614s 12s/step - loss: 1.2330 - acc: 0.4868 - val_loss: 0.8268 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7270 - acc: 0.5104\n",
            "Epoch 2: val_loss did not improve from 0.82684\n",
            "45/45 [==============================] - 101s 2s/step - loss: 0.7270 - acc: 0.5104 - val_loss: 0.8893 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7244 - acc: 0.5251\n",
            "Epoch 3: val_loss did not improve from 0.82684\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.7244 - acc: 0.5251 - val_loss: 0.8675 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7162 - acc: 0.5160\n",
            "Epoch 4: val_loss did not improve from 0.82684\n",
            "45/45 [==============================] - 97s 2s/step - loss: 0.7162 - acc: 0.5160 - val_loss: 0.8278 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7065 - acc: 0.5111\n",
            "Epoch 5: val_loss improved from 0.82684 to 0.79755, saving model to files/model.h5\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.7065 - acc: 0.5111 - val_loss: 0.7975 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7022 - acc: 0.5139\n",
            "Epoch 6: val_loss improved from 0.79755 to 0.77354, saving model to files/model.h5\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.7022 - acc: 0.5139 - val_loss: 0.7735 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.5258\n",
            "Epoch 7: val_loss improved from 0.77354 to 0.74591, saving model to files/model.h5\n",
            "45/45 [==============================] - 136s 3s/step - loss: 0.6938 - acc: 0.5258 - val_loss: 0.7459 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6818 - acc: 0.5376\n",
            "Epoch 8: val_loss improved from 0.74591 to 0.72492, saving model to files/model.h5\n",
            "45/45 [==============================] - 121s 3s/step - loss: 0.6818 - acc: 0.5376 - val_loss: 0.7249 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6692 - acc: 0.5669\n",
            "Epoch 9: val_loss improved from 0.72492 to 0.71182, saving model to files/model.h5\n",
            "45/45 [==============================] - 134s 3s/step - loss: 0.6692 - acc: 0.5669 - val_loss: 0.7118 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6605 - acc: 0.5766\n",
            "Epoch 10: val_loss did not improve from 0.71182\n",
            "45/45 [==============================] - 97s 2s/step - loss: 0.6605 - acc: 0.5766 - val_loss: 0.7125 - val_acc: 0.4519 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6521 - acc: 0.5947\n",
            "Epoch 11: val_loss improved from 0.71182 to 0.71009, saving model to files/model.h5\n",
            "45/45 [==============================] - 191s 4s/step - loss: 0.6521 - acc: 0.5947 - val_loss: 0.7101 - val_acc: 0.4874 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6425 - acc: 0.6121\n",
            "Epoch 12: val_loss did not improve from 0.71009\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.6425 - acc: 0.6121 - val_loss: 0.7441 - val_acc: 0.4540 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6450 - acc: 0.5982\n",
            "Epoch 13: val_loss did not improve from 0.71009\n",
            "45/45 [==============================] - 97s 2s/step - loss: 0.6450 - acc: 0.5982 - val_loss: 0.7753 - val_acc: 0.4393 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6461 - acc: 0.6024\n",
            "Epoch 14: val_loss did not improve from 0.71009\n",
            "45/45 [==============================] - 97s 2s/step - loss: 0.6461 - acc: 0.6024 - val_loss: 0.7324 - val_acc: 0.4540 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6214 - acc: 0.6295\n",
            "Epoch 15: val_loss improved from 0.71009 to 0.68296, saving model to files/model.h5\n",
            "45/45 [==============================] - 144s 3s/step - loss: 0.6214 - acc: 0.6295 - val_loss: 0.6830 - val_acc: 0.5084 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5873 - acc: 0.6748\n",
            "Epoch 16: val_loss improved from 0.68296 to 0.68258, saving model to files/model.h5\n",
            "45/45 [==============================] - 194s 4s/step - loss: 0.5873 - acc: 0.6748 - val_loss: 0.6826 - val_acc: 0.5607 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5591 - acc: 0.6978\n",
            "Epoch 17: val_loss improved from 0.68258 to 0.59758, saving model to files/model.h5\n",
            "45/45 [==============================] - 183s 4s/step - loss: 0.5591 - acc: 0.6978 - val_loss: 0.5976 - val_acc: 0.6255 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5445 - acc: 0.7033\n",
            "Epoch 18: val_loss did not improve from 0.59758\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.5445 - acc: 0.7033 - val_loss: 0.6690 - val_acc: 0.5983 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5457 - acc: 0.7110\n",
            "Epoch 19: val_loss improved from 0.59758 to 0.55787, saving model to files/model.h5\n",
            "45/45 [==============================] - 160s 4s/step - loss: 0.5457 - acc: 0.7110 - val_loss: 0.5579 - val_acc: 0.6799 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.4704 - acc: 0.7751\n",
            "Epoch 20: val_loss improved from 0.55787 to 0.55384, saving model to files/model.h5\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.4704 - acc: 0.7751 - val_loss: 0.5538 - val_acc: 0.6925 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.4504 - acc: 0.7827\n",
            "Epoch 21: val_loss improved from 0.55384 to 0.53763, saving model to files/model.h5\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.4504 - acc: 0.7827 - val_loss: 0.5376 - val_acc: 0.7092 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.4630 - acc: 0.7869\n",
            "Epoch 22: val_loss improved from 0.53763 to 0.41615, saving model to files/model.h5\n",
            "45/45 [==============================] - 165s 4s/step - loss: 0.4630 - acc: 0.7869 - val_loss: 0.4161 - val_acc: 0.7824 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3926 - acc: 0.8224\n",
            "Epoch 23: val_loss improved from 0.41615 to 0.37001, saving model to files/model.h5\n",
            "45/45 [==============================] - 160s 4s/step - loss: 0.3926 - acc: 0.8224 - val_loss: 0.3700 - val_acc: 0.8431 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.4195 - acc: 0.7953\n",
            "Epoch 24: val_loss did not improve from 0.37001\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.4195 - acc: 0.7953 - val_loss: 0.6145 - val_acc: 0.6506 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3901 - acc: 0.8238\n",
            "Epoch 25: val_loss improved from 0.37001 to 0.34509, saving model to files/model.h5\n",
            "45/45 [==============================] - 141s 3s/step - loss: 0.3901 - acc: 0.8238 - val_loss: 0.3451 - val_acc: 0.8640 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2932 - acc: 0.8795\n",
            "Epoch 26: val_loss improved from 0.34509 to 0.32178, saving model to files/model.h5\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.2932 - acc: 0.8795 - val_loss: 0.3218 - val_acc: 0.8431 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2637 - acc: 0.8907\n",
            "Epoch 27: val_loss improved from 0.32178 to 0.29320, saving model to files/model.h5\n",
            "45/45 [==============================] - 139s 3s/step - loss: 0.2637 - acc: 0.8907 - val_loss: 0.2932 - val_acc: 0.8766 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2294 - acc: 0.9095\n",
            "Epoch 28: val_loss did not improve from 0.29320\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.2294 - acc: 0.9095 - val_loss: 0.3248 - val_acc: 0.8640 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2485 - acc: 0.9004\n",
            "Epoch 29: val_loss did not improve from 0.29320\n",
            "45/45 [==============================] - 101s 2s/step - loss: 0.2485 - acc: 0.9004 - val_loss: 0.3035 - val_acc: 0.8598 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2456 - acc: 0.8983\n",
            "Epoch 30: val_loss improved from 0.29320 to 0.26672, saving model to files/model.h5\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.2456 - acc: 0.8983 - val_loss: 0.2667 - val_acc: 0.8912 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1673 - acc: 0.9450\n",
            "Epoch 31: val_loss did not improve from 0.26672\n",
            "45/45 [==============================] - 101s 2s/step - loss: 0.1673 - acc: 0.9450 - val_loss: 0.3261 - val_acc: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2037 - acc: 0.9199\n",
            "Epoch 32: val_loss improved from 0.26672 to 0.19967, saving model to files/model.h5\n",
            "45/45 [==============================] - 169s 4s/step - loss: 0.2037 - acc: 0.9199 - val_loss: 0.1997 - val_acc: 0.9163 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1893 - acc: 0.9185\n",
            "Epoch 33: val_loss did not improve from 0.19967\n",
            "45/45 [==============================] - 101s 2s/step - loss: 0.1893 - acc: 0.9185 - val_loss: 0.2561 - val_acc: 0.9079 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1527 - acc: 0.9408\n",
            "Epoch 34: val_loss did not improve from 0.19967\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.1527 - acc: 0.9408 - val_loss: 0.2001 - val_acc: 0.9289 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1356 - acc: 0.9457\n",
            "Epoch 35: val_loss did not improve from 0.19967\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.1356 - acc: 0.9457 - val_loss: 0.2513 - val_acc: 0.9017 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1386 - acc: 0.9478\n",
            "Epoch 36: val_loss did not improve from 0.19967\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.1386 - acc: 0.9478 - val_loss: 0.2274 - val_acc: 0.9017 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1143 - acc: 0.9554\n",
            "Epoch 37: val_loss improved from 0.19967 to 0.16760, saving model to files/model.h5\n",
            "45/45 [==============================] - 165s 4s/step - loss: 0.1143 - acc: 0.9554 - val_loss: 0.1676 - val_acc: 0.9331 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1295 - acc: 0.9450\n",
            "Epoch 38: val_loss did not improve from 0.16760\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.1295 - acc: 0.9450 - val_loss: 0.2583 - val_acc: 0.8996 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2089 - acc: 0.9150\n",
            "Epoch 39: val_loss did not improve from 0.16760\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.2089 - acc: 0.9150 - val_loss: 0.5169 - val_acc: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1581 - acc: 0.9450\n",
            "Epoch 40: val_loss did not improve from 0.16760\n",
            "45/45 [==============================] - 97s 2s/step - loss: 0.1581 - acc: 0.9450 - val_loss: 0.1755 - val_acc: 0.9289 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0845 - acc: 0.9694\n",
            "Epoch 41: val_loss improved from 0.16760 to 0.15777, saving model to files/model.h5\n",
            "45/45 [==============================] - 142s 3s/step - loss: 0.0845 - acc: 0.9694 - val_loss: 0.1578 - val_acc: 0.9435 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2309 - acc: 0.9143\n",
            "Epoch 42: val_loss did not improve from 0.15777\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.2309 - acc: 0.9143 - val_loss: 0.2566 - val_acc: 0.9059 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1400 - acc: 0.9526\n",
            "Epoch 43: val_loss did not improve from 0.15777\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.1400 - acc: 0.9526 - val_loss: 0.2323 - val_acc: 0.9121 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1137 - acc: 0.9547\n",
            "Epoch 44: val_loss did not improve from 0.15777\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.1137 - acc: 0.9547 - val_loss: 0.2225 - val_acc: 0.9247 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1980 - acc: 0.9255\n",
            "Epoch 45: val_loss did not improve from 0.15777\n",
            "45/45 [==============================] - 97s 2s/step - loss: 0.1980 - acc: 0.9255 - val_loss: 0.2684 - val_acc: 0.8996 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1142 - acc: 0.9547\n",
            "Epoch 46: val_loss did not improve from 0.15777\n",
            "45/45 [==============================] - 100s 2s/step - loss: 0.1142 - acc: 0.9547 - val_loss: 0.2866 - val_acc: 0.8891 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 144). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "    from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False),\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        epochs=hp[\"num_epochs\"],\n",
        "        validation_data=valid_ds,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    model.save('/content/drive/MyDrive/MonReader/files/my_model_entire')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights\n",
        "model.save_weights('/content/drive/MyDrive/MonReader/files/model.h5')"
      ],
      "metadata": {
        "id": "zoPdDe3Om_uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/MonReader/files/my_model')"
      ],
      "metadata": {
        "id": "5BuMD1K6qi2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6b60e3-7d66-4d72-bea0-5f52fa351d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 144). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/MonReader/files/model.h5')"
      ],
      "metadata": {
        "id": "Z2DDYg1e37hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IYhCiGFFZANJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf_dataset(test_x, batch=hp['batch_size'])\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVJbb72v7mPS",
        "outputId": "0ece1b96-58a8-4706-bd6d-6845dfa6d025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 163s 8s/step - loss: 0.3016 - acc: 0.8995\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3015839159488678, 0.8994975090026855]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecfV0jrX-nK-",
        "outputId": "4769af7f-4ace-4881-f494-cc680548ef8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 30s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the predicted labels"
      ],
      "metadata": {
        "id": "3pViw4BRFVU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_labels = np.argmax(test_predictions, axis=1)\n",
        "binary_labels\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKIStDAx_zjV",
        "outputId": "28a6f015-e8b3-4de1-f5c9-70c28a5da5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the test labels"
      ],
      "metadata": {
        "id": "J6Dnsj4lFTm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "\n",
        "for patches, labels in test_ds:\n",
        "    label_list.extend(labels)\n",
        "\n",
        "# Convert the labels based on the specified conditions\n",
        "converted_labels = [0 if label[0] == 1 else 1 for label in label_list]\n",
        "\n",
        "print(converted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj-qjadJDKAX",
        "outputId": "94c47f68-291c-45bf-fc11-6a6c44deaad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Compute confusion matrix\n",
        "confusion_mat = confusion_matrix(converted_labels, binary_labels)\n",
        "\n",
        "# Create a heatmap plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mY58IyOm75yT",
        "outputId": "558ae151-e72c-43b9-d376-1b0dd99a3913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vision Transformer summary\n",
        "\n",
        "Training accuracy: 0.96\n",
        "\n",
        "Loss: 0.0845\n",
        "\n",
        "validation accuracy: 0.94\n",
        "\n",
        "Validation loss: 0.16\n",
        "\n",
        "Test accuracy: 0.9\n",
        "\n",
        "Test loss: 0.3\n",
        "\n",
        "## 2D CNN\n",
        "\n",
        "Results for the test data:\n",
        "          precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.93      0.96       290\n",
        "           1       0.94      1.00      0.97       307\n",
        "\n",
        "    accuracy                           0.96       597\n"
      ],
      "metadata": {
        "id": "C1ELgdfZYymb"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1xGFPCvCFiG5hYKuHT2qPEKzN-_F5MBQB",
      "authorship_tag": "ABX9TyNiBaZqxEvkDYHSC5qp28N6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}